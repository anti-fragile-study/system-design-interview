# Ch09. 웹 크롤러 설계

### 웹은 하이퍼링크를 통해 유향 그래프처럼 연결되어 있다. 크롤링 프로세스가 하이퍼링크를 타고 웹 페이지들을 탐색하기 위해 사용할 수 있는 알고리즘에는 무엇이 있는가?

* `BFS` 그래프 탐색 알고리즘을 사용한다면, 모든 웹 페이지를 순차적으로 탐색할 것이다. 이런 경우 발생할 수 있는 문제점에는 무엇이 있는가?
* 동일한 호스트에 동시 요청을 보내지 않는, 예의를 갖춘 크롤러를 구현하기 위한 방법에는 무엇이 있는가?

<details>
<summary><h4>해설</h4></summary>

> 웹은 하이퍼링크를 통해 유향 그래프처럼 연결되어 있다. 크롤링 프로세스가 하이퍼링크를 타고 웹 페이지들을 탐색하기 위해 사용할 수 있는 알고리즘에는 무엇이 있는가?
* 그래프 탐색 알고리즘에는 대표적으로 `BFS`와 `DFS`가 있다. 그러나 방대한 웹을 `DFS`로 탐색하기에는 어느 정도 깊숙이 탐색하게 될지 알 수 없다. 따라서 `BFS`가 적절할 것이다.

> `BFS` 그래프 탐색 알고리즘을 사용한다면, 연결된 모든 링크를 순차적으로 탐색할 것이다. 이런 경우 발생할 수 있는 문제점에는 무엇이 있는가?
* 일반적으로 한 페이지에서 나오는 링크의 상당수는 같은 서버로 되돌아간다. 만약 `BFS` 알고리즘을 사용한다면, 크롤러는 동일한 호스트에 속한 많을 링크에 동시 요청을 보내게 될 것이다. 
* 호스트는 수많은 요청으로 인해 과부하에 걸리게 될 것이며, 이런 크롤러는 예의 없는 크롤러로 간주된다.

> 동일한 호스트에 동시 요청을 보내지 않는, 예의를 갖춘 크롤러를 구현하기 위한 방법에는 무엇이 있는가?
* 예의를 갖춘 크롤러를 만드려면 동일 웹 사이트에 대해서는 한 번에 한 페이지만 요청해야 한다. 
* 따라서 별도의 라우터를 두어 같은 호스트에 속한 URL은 언제나 같은 서버나 작업 스레드에서 순차적으로 처리하도록 해야한다.
</details>


<br>

### 웹 크롤러가 이미 방문한 URL을 다시 방문하지 않도록 처리하는 방법에는 무엇이 있는가?

* 많은 웹사이트가 클라이언트 사이드 렌더링을 수행하고 있다. 이런 경우 크롤링에는 어떤 어려움이 있을 수 있는가?
* 클라이언트 사이드 렌더링을 수행하는 웹 페이지에서 동적 데이터를 크롤링하기 위해서 어떤 방법을 사용할 수 있는가?

<details>
<summary><h4>해설</h4></summary>

> 웹 크롤러가 이미 방문한 URL을 다시 방문하지 않도록 처리하는 방법에는 무엇이 있는가?
* 이미 다운로드 완료한 URL을 디스크에 저장하고, 새로운 URL을 찾아낸 경우 디스크에 저장되어 있는지 검사한다.
* 자주 사용되는 URL의 경우 메모리에 저장해 처리 속도를 향상시킬 수 있다.

> 많은 웹사이트가 클라이언트 사이드 렌더링을 수행하고 있다. 이런 경우 크롤링에는 어떤 어려움이 있을 수 있는가?
* 클라이언트 사이드 렌더링을 수행할 경우, 브라우저에서 스크립트를 수행해 데이터를 가져와 페이지를 완성한다.
* 따라서 웹페이지를 있는 그대로 다운받아 파싱한다면 동적으로 생성되는 링크를 발견할 수 없게 된다.

> 클라이언트 사이드 렌더링을 수행하는 웹 페이지에서 동적 데이터를 크롤링하기 위해서 어떤 방법을 사용할 수 있는가?
* 클라이언트 사이드 렌더링을 수행할 경우, 브라우저에서 서버에 요청을 보내 페이지를 완성한 이후에 크롤링을 수행해야 한다.
* 대표적으로는 셀레니움을 사용해 브라우저를 실행시켜 동적 데이터를 받아올 수 있다.
</details>
